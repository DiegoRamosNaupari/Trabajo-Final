{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c941403",
   "metadata": {},
   "source": [
    "<h1><center>web Scraping UniProt</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b66d98",
   "metadata": {},
   "source": [
    "<center><img src='data:image/png;base64,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'></img></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba66f2d",
   "metadata": {},
   "source": [
    "### Librery BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc246df",
   "metadata": {},
   "source": [
    "Beautiful Soup es una librería Python que permite extraer información de contenido en formato *HTML o XML*. Para usarla, es necesario especificar un parser, que es responsable de transformar un documento *HTML o XML* en un árbol complejo de objetos Python. Esto permite, por ejemplo, que podamos interactuar con los elementos de una página web como si estuviésemos utilizando las herramientas del desarrollador de un navegador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c576daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos las librerias a usar para hacer el web scraping\n",
    "\n",
    "from bs4 import BeautifulSoup   # importa la libreria Beautifulsoup\n",
    "import requests                 # importa la libreria requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76e300a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd   #importa la libreria pandas "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1431faf2",
   "metadata": {},
   "source": [
    "Importamos la libreria $pandas$ la cual es de mucha utilidad al momento de realizar $WebScraping$  o al menos en nuestro caso ya que al final tenemos que presentarlo como un cuadro de $excel$ y para ello debemos transformalo previamente en un ***data frame*** , lo cual sera posible gracias a la funcion de pandas y para que al moment de llamarlo no sea tan complicado lo llamares como **pd**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22a1b97",
   "metadata": {},
   "source": [
    "### Librery openpyxl\n",
    "\n",
    "* Es una biblioteca de python que sirve para leer y escribir archivos xlxs y xlsxm de excel.\n",
    "* Nacio de la falta de una biblioteca existente para leer.\n",
    "*[Librery Openpyxl](https://pypi.org/project/openpyxl/) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07cb8bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl                 # importa la libreria openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba91073",
   "metadata": {},
   "source": [
    "* Ahora creamos un objeto que me permita direccionar a mi carpeta de trabajo y el excel Tablasvacia.xlsx\n",
    "* Leeremos la fila 1 y primera columna de los genes para agregarlo en una lista y nuestra lectura sea mas comoda.\n",
    "\n",
    "**NOTA:**\n",
    "\n",
    "**La dirección de la carpeta de trabajo variara depende del compañero ya que cada uno hemos ubicado su ruta en su PC**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ef51c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "archivo_excel_vacio = pd.read_excel(\"C:/Users/User/OneDrive/Documentos/Escritorio/LP2/Tablasvaciasoficial.xlsx\",header=1,index_col=0)  # leer excel de cabecera fila 1 y indice columna 0\n",
    "lista_genes_abreviados=list(archivo_excel_vacio[\"GEN ABREV\"])  # importamos la columna que tiene los genes abreviados y los introducimos a una lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44f3d6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cambiamos la ruta contantemente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8b7536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : TRNAS-GGA\n",
      "2 : LOC102173449\n",
      "3 : LOC102169333\n",
      "4 : LOC108636757\n",
      "5 : LOC102187712\n",
      "6 : VGLL3\n",
      "7 : CHMP2B\n",
      "8 : POU1F1\n",
      "9 : HTR1F\n",
      "10 : LOC102188976\n",
      "11 : CGGBP1\n",
      "12 : ZNF654\n",
      "13 : C1H3orf38\n",
      "14 : LOC102190548\n",
      "15 : SLC12A8\n",
      "16 : LOC106502043\n",
      "17 : ZNF148\n",
      "18 : SNX4\n",
      "19 : OSBPL11\n",
      "20 : LMLN\n",
      "21 : RPL35A\n",
      "22 : IQCG\n",
      "23 : LRCH3\n",
      "24 : FYTTD1\n",
      "25 : RUBCN\n",
      "26 : MUC20\n",
      "27 : MUC4\n",
      "28 : TNK2\n",
      "29 : TFRC\n",
      "30 : ZDHHC19\n",
      "31 : SLC51A\n",
      "32 : PCYT1A\n",
      "33 : TCTEX1D2\n",
      "34 : TM4SF19\n",
      "35 : UBXN7\n",
      "36 : LOC102173689\n",
      "37 : LOC106501980\n",
      "38 : RNF168\n",
      "39 : SMCO1\n",
      "40 : WDR53\n",
      "41 : FBXO45\n",
      "42 : LOC102175715\n",
      "43 : NRROS\n",
      "44 : CEP19\n",
      "45 : PIGX\n",
      "46 : PAK2\n",
      "47 : LOC108635601\n",
      "48 : SENP5\n",
      "49 : NCBP2\n",
      "50 : PIGZ\n",
      "51 : LOC102176365\n",
      "52 : MELTF\n",
      "53 : RTP2\n",
      "54 : SST\n",
      "55 : RTP4\n",
      "56 : LOC102171192\n",
      "57 : MASP1\n",
      "58 : RTP1\n",
      "59 : LOC102179137\n",
      "60 : ST6GAL1\n",
      "61 : TRNAK-UUU\n",
      "62 : ADIPOQ\n",
      "63 : RFC4\n",
      "64 : EIF4A2\n",
      "65 : MIR1248\n",
      "66 : KNG1\n",
      "67 : HRG\n",
      "68 : FETUB\n",
      "69 : AHSG\n",
      "70 : LOC108635832\n",
      "71 : DNAJB11\n",
      "72 : TBCCD1\n",
      "73 : CRYGS\n",
      "74 : DGKG\n",
      "75 : ETV5\n",
      "76 : LOC102179418\n",
      "77 : LOC108635834\n",
      "78 : LOC102178398\n",
      "79 : IGF2BP2\n",
      "80 : SENP2\n",
      "81 : POLR2H\n",
      "82 : CLCN2\n",
      "83 : LOC106502122\n",
      "84 : FAM131A\n",
      "85 : EIF4G1\n",
      "86 : PSMD2\n",
      "87 : ECE2\n",
      "88 : CAMK2N2\n",
      "89 : ALG3\n",
      "90 : MIR1224\n",
      "91 : ABCF3\n",
      "92 : AP2M1\n",
      "93 : DVL3\n",
      "94 : EIF2B5\n",
      "95 : LOC102185396\n",
      "96 : LOC102185870\n",
      "97 : LOC102183010\n",
      "98 : LOC108636852\n",
      "99 : LOC102183269\n",
      "100 : ABCC5\n",
      "101 : LOC102183549\n",
      "102 : PARL\n",
      "103 : MAP6D1\n",
      "104 : YEATS2\n",
      "105 : LOC102187268\n",
      "106 : KLHL24\n",
      "107 : LOC108636351\n",
      "108 : KLHL6\n",
      "109 : LOC102188899\n",
      "110 : MCF2L2\n",
      "111 : LOC102189625\n",
      "112 : LOC108635871\n",
      "113 : B3GNT5\n",
      "114 : LOC106501989\n",
      "115 : LAMP3\n",
      "116 : MCCC1\n",
      "117 : DCUN1D1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Ahora usaremos un bucle for para recorrer los elementos de un objeto iterable\n",
    "#y ejecutar un bloque de código.\n",
    "\n",
    "m=3          # se incia en la fila 3\n",
    "for i in lista_genes_abreviados:    # lee cada abreviación del gen\n",
    "    print(m-2,\":\",i)                # imprime la fila y el gen que se esta procesando\n",
    "    URL=f\"https://www.uniprot.org/uniprot/?query={i.upper()}+capra+hircus&sort=score\"   # introducimos el url de busqueda de la pagina requerida\n",
    "    page=requests.get(URL)         # conección a la pagina\n",
    "    soup=BeautifulSoup(page.content,\"html.parser\")  # almacena el codigo html\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    # hacemos una lista que lamaemos indice ,al cual se ira almacenando , debido a que haremos una iteraion con for , \n",
    "    #la cual nos servirara luego , esta lista almacenara a todos los valores de genes que fuimos leyendo ,le agregamos un append para que lo agregue \n",
    "\n",
    "    link_entry=soup.find_all(\"td\",class_=\"entryID\")  # lista de entradas que aparacen en el resultado de la busqueda\n",
    "    indice=[]                      # genera una lista vacia\n",
    "    for P in link_entry:           # para cada entrada que aparece en el resultado de busqueda se almacena en la lista indice \n",
    "        indice.append(P.text)      # añade los resultados a la lista vacia\n",
    "    try:                      # si hay un resultado en el indice va intentar ejecutar el siguiente codigo\n",
    "        FINAL=indice[0]       # selecciona el primer resultado\n",
    "        url=f\"https://www.uniprot.org/uniprot/{FINAL}\" # introduce el url del primer resultado\n",
    "        page=requests.get(url)                      # conección a la pagina\n",
    "        soup=BeautifulSoup(page.content,\"html.parser\")  # almacena el codigo html\n",
    "               \n",
    "\n",
    "#LLENAREMOS LAS COLUMNAS CON LA INFORMACION DADA POR LA WEB  \n",
    "\n",
    "        #ENTRY Y ENTRY NAME\n",
    "        entry_name=soup.find_all(\"h2\",class_=\"page-title\")  # busca todos los elementos que tengan etiqueta h2\n",
    "        for Q in entry_name:                                # limpia los resultados y extrae unicamente los textos\n",
    "            entry1=Q.text                                # extrae unicamente los textos\n",
    "        entry1=entry1.split()                            # separa los textos encontrados\n",
    "        ENTRY=entry1[2]                                  # selecciona el elemento número 2 de los textos\n",
    "        ENTRY_NAME=\"\".join(list(entry1[3])[1:len(list(entry1[3]))-1])  # introduce lo encontrado anteriormente y lo selecciona como entry_name\n",
    "\n",
    "        #PROTEINA\n",
    "        protein=soup.find_all(\"h1\",property=\"name\") # busca todos los elementos que tenga etiqueta h1\n",
    "        for Q in protein:              # limpia los resultados\n",
    "            PROTEIN=Q.text            # extrae unicamente los textos\n",
    "\n",
    "\n",
    "        #GEN\n",
    "        gen_abrev=soup.find_all(\"div\",class_='entry-overview-content',id=\"content-gene\")  # busca todos los elementos que contienen id \"content-gene\", con etiqueta div.\n",
    "        for Q in gen_abrev:    # limpia los resultados\n",
    "            GEN_ABREV=Q.text    # extrae unicamente los textos\n",
    "\n",
    "        #ORGANISMO\n",
    "        organismo=soup.find_all(\"div\",class_='entry-overview-content',id=\"content-organism\")  # busca todos los elementos que contienen id \"content-organism\", con etiqueta div.\n",
    "        for Q in organismo:    # limpia los resultados\n",
    "            ORGANISMO=Q.text   # extrae unicamente los textos\n",
    "\n",
    "            \n",
    "###aumeno la columna status         \n",
    "        #STATUS\n",
    "        status=soup.find_all(\"span\",class_='context-help bin-score tooltipped-click')  # busca todos los elementos, con etiqueta span.\n",
    "        for Q in status:       # limpia los resultados\n",
    "            STATUS_PRE=Q.text   # extrae unicamente los textos\n",
    "        STATUS=STATUS_PRE.split(\"\\n\")[0].split(\":\")[1]  # selecciona el status de toda esa respuesta\n",
    "\n",
    "\n",
    "###agreo la ultima columna\n",
    "        #GO BIOLOGICAL PROCESS\n",
    "        bio_process=soup.find_all(\"a\",onclick=\"window.ga('UniProt-Entry-View', 'click', 'Display-GO-Term');\")  # busca todos los elementos, con etiqueta a\n",
    "        BIO_PROCESS=[]     # crea una lista\n",
    "        for Q in bio_process:  # limpia los resultados\n",
    "            BIO_PROCESS.append(Q.text)  # selecciona los textos y los añade a la lista vacia\n",
    "        BIO_PROCESS=str(BIO_PROCESS)   # vuelve toda la lista en una cadena\n",
    "        \n",
    " \n",
    "\n",
    " ###si es que no hay resultado en la busqueda dejaremos en blanco las celdas de los siguientes atributos     \n",
    "    except:               \n",
    "        ENTRY=\"\"\n",
    "        ENTRY_NAME=\"\"\n",
    "        PROTEIN=\"\"\n",
    "        GEN_ABREV=\"\"\n",
    "        ORGANISMO=\"\"\n",
    "        STATUS=\"\"\n",
    "        BIO_PROCESS=\"\"\n",
    "\n",
    "####lo vinculamos con el excel que trabajaremos        \n",
    "    excel=openpyxl.load_workbook(\"C:/Users/User/OneDrive/Documentos/Escritorio/LP2/Tablasvaciasoficial.xlsx\")  # abre el excel para completar los datos obtenidos en las columnas\n",
    "\n",
    "#agregamos para adjuntar aa hoja la cual escribira\n",
    "\n",
    "    sheet=excel['Hoja1']                # hoja 1 del excel\n",
    "    sheet.cell(row=m,column=3).value = ENTRY    # llena los valores\n",
    "    sheet.cell(row=m,column=4).value = ENTRY_NAME\n",
    "    sheet.cell(row=m,column=5).value = PROTEIN\n",
    "    sheet.cell(row=m,column=6).value = GEN_ABREV\n",
    "    sheet.cell(row=m,column=7).value = ORGANISMO\n",
    "    sheet.cell(row=m,column=8).value = STATUS\n",
    "    sheet.cell(row=m,column=9).value = BIO_PROCESS\n",
    "    \n",
    "######NOTAAAAA#####    \n",
    "##############################################################################################\n",
    "### colocamos la direccion sobre el documento el cual queremos escribirtodo, LO SOBREESCRIBIREMOS\n",
    "#####################################################################################################\n",
    "    \n",
    "    excel.save('C:/Users/User/OneDrive/Documentos/Escritorio/LP2/tablapruebaaAAAaa.xlsx')  # guarda el excel con los datos obtenidos\n",
    "    m=m+1                    # pasa a la siguiente fila"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd847f4c",
   "metadata": {},
   "source": [
    "* En ese cuadro entre michis $#$  si queremos crear un nuevo excel en la ultima ruta colacamos la de un excel vacio y esta se llenara de igual manera"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5428ca39",
   "metadata": {},
   "source": [
    "* Tener encuenta que para que pueda llenar los datos al excel debemos tener cerrado el excel, porque sino nos saldria error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fa6e66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
