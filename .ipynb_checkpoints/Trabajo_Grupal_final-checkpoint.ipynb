{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>web Scraping UniProt</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src='data:image/png;base64,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'></img></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Librery BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beautiful Soup es una librería Python que permite extraer información de contenido en formato *HTML o XML*. Para usarla, es necesario especificar un parser, que es responsable de transformar un documento *HTML o XML* en un árbol complejo de objetos Python. Esto permite, por ejemplo, que podamos interactuar con los elementos de una página web como si estuviésemos utilizando las herramientas del desarrollador de un navegador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos las librerias a usar para hacer el web scraping\n",
    "\n",
    "from bs4 import BeautifulSoup   # importa la libreria Beautifulsoup\n",
    "import requests                 # importa la libreria requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd   #importa la libreria pandas "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos la libreria $pandas$ la cual es de mucha utilidad al momento de realizar $WebScraping$  o al menos en nuestro caso ya que al final tenemos que presentarlo como un cuadro de $excel$ y para ello debemos transformalo previamente en un ***data frame*** , lo cual sera posible gracias a la funcion de pandas y para que al moment de llamarlo no sea tan complicado lo llamares como **pd**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Librery openpyxl\n",
    "\n",
    "* Es una biblioteca de python que sirve para leer y escribir archivos xlxs y xlsxm de excel.\n",
    "* Nacio de la falta de una biblioteca existente para leer.\n",
    "*[Librery Openpyxl](https://pypi.org/project/openpyxl/) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl                 # importa la libreria openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Ahora creamos un objeto que me permita direccionar a mi carpeta de trabajo y el excel Tablasvacia.xlsx\n",
    "* Leeremos la fila 1 y primera columna de los genes para agregarlo en una lista y nuestra lectura sea mas comoda.\n",
    "\n",
    "**NOTA:**\n",
    "\n",
    "**La dirección de la carpeta de trabajo variara depende del compañero ya que cada uno hemos ubicado su ruta en su PC**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivo_excel_vacio = pd.read_excel(\"C:/Users/kelly/Desktop/LP2/Tablasvaciasoficial.xlsx\",header=1,index_col=0)  # leer excel de cabecera fila 1 y indice columna 0                                                                         \n",
    "lista_genes_abreviados=list(archivo_excel_vacio[\"GEN ABREV\"])  # importamos la columna que tiene los genes abreviados y los introducimos a una lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cambiamos la ruta contantemente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-17-7f3683763f74>, line 57)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-17-7f3683763f74>\"\u001b[1;36m, line \u001b[1;32m57\u001b[0m\n\u001b[1;33m    \u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "#Ahora usaremos un bucle for para recorrer los elementos de un objeto iterable\n",
    "#y ejecutar un bloque de código.\n",
    "\n",
    "m=3          # se incia en la fila 3\n",
    "\n",
    "for i in lista_genes_abreviados:    # lee cada abreviación del gen\n",
    "    print(m-2,\":\",i)                # imprime la fila y el gen que se esta procesando\n",
    "    URL=f\"https://www.uniprot.org/uniprot/?query={i.upper()}+capra+hircus&sort=score\"   # introducimos el url de busqueda de la pagina requerida\n",
    "    page=requests.get(URL)         # Esto nos indica la conección a la pagina\n",
    "    soup=BeautifulSoup(page.content,\"html.parser\")  # almacena el codigo html\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    # hacemos una lista que lamaemos indice ,al cual se ira almacenando , debido a que haremos una iteraion con for , \n",
    "    #la cual nos servirara luego , esta lista almacenara a todos los valores de genes que fuimos leyendo ,le agregamos un append para que lo agregue \n",
    "\n",
    "    link_entry=soup.find_all(\"td\",class_=\"entryID\")  # lista de entradas que aparacen en el resultado de la busqueda\n",
    "    indice=[]                      # genera una lista vacia\n",
    "    for P in link_entry:           # para cada entrada que aparece en el resultado de busqueda se almacena en la lista indice \n",
    "        indice.append(P.text)      # añade los resultados a la lista vacia\n",
    "    try:                      # si hay un resultado en el indice va intentar ejecutar el siguiente codigo\n",
    "        FINAL=indice[0]       # selecciona el primer resultado\n",
    "        url=f\"https://www.uniprot.org/uniprot/{FINAL}\" # introduce el url del primer resultado\n",
    "        page=requests.get(url)                      # conección a la pagina\n",
    "        soup=BeautifulSoup(page.content,\"html.parser\")  # almacena el codigo html\n",
    "\n",
    "\n",
    "#LLENAREMOS LAS COLUMNAS CON LA INFORMACION DADA }POR LA WEB  \n",
    "\n",
    "        # ENTRY Y ENTRY NAME:\n",
    "\n",
    "        #Hacemos un for para así poder extraer los datos de las 2 primeras columnas desde la pagina web \n",
    "\n",
    "        entry_name=soup.find_all(\"h2\",class_=\"page-title\")  # busca todos los elementos que tengan etiqueta h2\n",
    "        for Q in entry_name:                                # limpia los resultados y extrae unicamente los textos            \n",
    "            entry1=Q.text                                # extrae unicamente los textos\n",
    "        entry1=entry1.split()                            # separa los textos encontrados\n",
    "        ENTRY=entry1[2]                                  # selecciona el elemento número 2 de los textos\n",
    "        ENTRY_NAME=\"\".join(list(entry1[3])[1:len(list(entry1[3]))-1])  # introduce lo encontrado anteriormente y lo selecciona como entry_name\n",
    "\n",
    "        #PROTEINA\n",
    "        protein=soup.find_all(\"h1\",property=\"name\") # busca todos los elementos que tenga etiqueta h1\n",
    "        for Q in protein:              # limpia los resultados\n",
    "            PROTEIN=Q.text            # extrae unicamente los textos\n",
    "\n",
    "\n",
    "        #GEN\n",
    "        gen_abrev=soup.find_all(\"div\",class_='entry-overview-content',id=\"content-gene\")  # busca todos los elementos que contienen id \"content-gene\", con etiqueta div.\n",
    "        for Q in gen_abrev:    # limpia los resultados\n",
    "            GEN_ABREV=Q.text    # extrae unicamente los textos\n",
    "\n",
    "        #ORGANISMO\n",
    "        organismo=soup.find_all(\"div\",class_='entry-overview-content',id=\"content-organism\")  # busca todos los elementos que contienen id \"content-organism\", con etiqueta div.\n",
    "        for Q in organismo:    # limpia los resultados\n",
    "            ORGANISMO=Q.text   # extrae unicamente los textos\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
